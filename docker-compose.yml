# The version of the docker-compose standard being followed here
version: '3'

# Services are groups of containers handling one aspect of the application
services:
  database: # PostgreSQL
    image: postgres:alpine

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 5432 used by PostgreSQL to other containers
    expose:
      - "5432"

    # Run the container as the non-root user
    user: postgres

    # Set the environment variables
    env_file:
    - postgres/database.env

    # Mount the volumes on the database container
    volumes:
      # Mount 'database' as the place where PostgreSQL stores all its data
      - database:/var/lib/postgresql/data

  channel-layer: # Redis
    # Use the Redis image from Alpine Linux as is
    image: redis:alpine

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 6379 used by Redis to other containers
    expose:
      - "6379"

    # Run the container as the non-root user
    user: redis

  session-store: # Redis
    # Use the Redis image from Alpine Linux as is
    image: redis:alpine

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 6379 used by Redis to other containers
    expose:
      - "6379"

    # Run the container as the non-root user
    user: redis

  message-broker: # RabbitMQ
    # Use the RabbitMQ image from Alpine Linux as is
    image: rabbitmq:management-alpine

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 5672 used by RabbitMQ to other containers
    expose:
      - "5672"

    # Expose the ports 15672 to the host at 5672 and 15672
    ports:
      - "15672:15672"

    # Run the container as the non-root user
    user: rabbitmq
    
    # Set the environment variables
    env_file:
    - rabbitmq/message_broker.env

  intranet-server: # Gunicorn + Daphne
    # Use the Django image we made ourselves by running ./scripts/build/django.sh
    image: omniport-django:latest

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the ports 8000 and 8001 used by Gunicorn and Daphne to other containers
    expose:
      - "8000"
      - "8001"

    # Run the container as the non-root user
    user: django

    # Set the SITE_ID environment variable so that the right JSON may be processed
    environment:
      - SITE_ID=1

    # Change the port to ensure that each site runs on its own port
    command: ["/usr/bin/supervisord", "-c", "/supervisord.conf"]

    # We mount the volumes on the Gunicorn container
    volumes:
      # Mount the code from the 'omniport' folder in the root of the container 
      - ./omniport:/omniport

      # Mount the images from logos into the static folder in Omniport
      - ./branding:/omniport/omniport/static/omniport/branding

      # Mount the JSON configuration files into the configuration folder in Omniport
      - ./configuration:/omniport/configuration
      
      # Mount 'media' as its namesake in the root of the container
      - media:/media

      # Mount 'web_server_logs' as its namesake in the root of the container
      - web_server_logs:/web_server_logs

    # The services that need to be ready before this one
    depends_on:
      - database
      - channel-layer
      - session-store
      - message-broker

  internet-server: # Gunicorn + Daphne
    # Use the Django image we made ourselves by running ./scripts/build/django.sh
    image: omniport-django:latest

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the ports 8000 and 8001 used by Gunicorn and Daphne to other containers
    expose:
      - "8000"
      - "8001"

    # Run the container as the non-root user
    user: django

    # Set the SITE_ID environment variable so that the right JSON may be processed
    environment:
      - SITE_ID=2

    command: ["/usr/bin/supervisord", "-c", "/supervisord.conf"]

    # We mount the volumes on the Gunicorn container
    volumes:
      # Mount the code from the 'omniport' folder in the root of the container 
      - ./omniport:/omniport

      # Mount the images from logos into the static folder in Omniport
      - ./branding:/omniport/omniport/static/omniport/branding

      # Mount the JSON configuration files into the configuration folder in Omniport
      - ./configuration:/omniport/configuration
      
      # Mount 'media' as its namesake in the root of the container
      - media:/media

      # Mount 'web_server_logs' as its namesake in the root of the container
      - web_server_logs:/web_server_logs

    # The services that need to be ready before this one
    depends_on:
      - database
      - channel-layer
      - session-store
      - message-broker

  reverse-proxy: # NGINX
    # Use the NGINX image we made ourselves by running ./scripts/build/nginx.sh
    image: omniport-nginx:latest

    # No matter what, if the container stops, start it again
    restart: always

    # Expose the port 80 and 443 used by NGINX to other containers
    expose:
      - "80"
      - "443"

    # Expose the ports 80 and 443 used by NGINX to the host
    ports:
      - "80:80"
      - "443:443"

    # Mount the volumes on the NGINX container
    volumes:
      # Mount the code from the 'omniport' folder in the root of the container 
      - ./omniport:/omniport

      # Mount 'media' as its namesake in the root of the container
      - media:/media

      # Mount 'reverse_proxy_logs' as its namesake in the root of the container
      - reverse_proxy_logs:/reverse_proxy_logs

    # The services that need to be ready before this one
    depends_on:
      - intranet-server
      - internet-server

# Volumes are virtual drives connected to containers
volumes:
  # This volume contains the database and PostgreSQL configuration files
  database:
  # This volume contains periodic dumps of the database for backup
  database_backup:

  # This volume contains reverse proxy logs
  reverse_proxy_logs:
  # This volume contains web server logs
  web_server_logs:

  # This volume contains the production build of all frontend apps
  frontend:

  # This volume contains the media files
  media:
  # This volume contains periodic dumps of the media files for backup
  media_backup:
